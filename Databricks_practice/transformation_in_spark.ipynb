{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5aa7f35-879a-480f-a68b-0bf1ce5d251c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n| id|    name|age|salary|     address| nominee|\n+---+--------+---+------+------------+--------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|  3|  Pritam| 22|150000|   Bangalore|   India|\n|  4|Prantosh| 17|200000|     Kolkata|   India|\n|  5|  Vikash| 31|300000|        null|nominee5|\n+---+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Reading data\n",
    "employee_data1 = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\",True)\\\n",
    "    .option(\"inferSchema\",True)\\\n",
    "    .option(\"mode\",\"PERMISSIVE\")\\\n",
    "    .load(\"/FileStore/tables/employee_data_csv-1.csv\")\n",
    "\n",
    "employee_data1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23eb4b99-819b-4f13-859e-52947efe60c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: integer (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c65f7d11-441e-40f0-b2b1-8d53e79bf92d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Select Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c21edac0-b9de-46ea-b0a6-c574317a4cac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|    name|\n+--------+\n|  Manish|\n|  Nikita|\n|  Pritam|\n|Prantosh|\n|  Vikash|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "509dd239-4c59-4d5d-b755-ddfe1209a43b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|    name|\n+--------+\n|  Manish|\n|  Nikita|\n|  Pritam|\n|Prantosh|\n|  Vikash|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(col(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0cfe81-bbf1-4ce3-a142-f869542e4bed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2960761336320886>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43memployee_data1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid + 5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n",
       "\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n",
       "\u001B[1;32m   2979\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n",
       "\u001B[1;32m   2980\u001B[0m \n",
       "\u001B[1;32m   2981\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3021\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n",
       "\u001B[1;32m   3022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m-> 3023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   3024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id + 5` cannot be resolved. Did you mean one of the following? [`id`, `address`, `age`, `name`, `nominee`].;\n",
       "'Project ['id + 5]\n",
       "+- Relation [id#1156,name#1157,age#1158,salary#1159,address#1160,nominee#1161] csv\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-2960761336320886>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43memployee_data1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid + 5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3023\u001B[0m, in \u001B[0;36mDataFrame.select\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m   2978\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mselect\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumnOrName\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   2979\u001B[0m     \u001B[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001B[39;00m\n\u001B[1;32m   2980\u001B[0m \n\u001B[1;32m   2981\u001B[0m \u001B[38;5;124;03m    .. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3021\u001B[0m \u001B[38;5;124;03m    +-----+---+\u001B[39;00m\n\u001B[1;32m   3022\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 3023\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jcols\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3024\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id + 5` cannot be resolved. Did you mean one of the following? [`id`, `address`, `age`, `name`, `nominee`].;\n'Project ['id + 5]\n+- Relation [id#1156,name#1157,age#1158,salary#1159,address#1160,nominee#1161] csv\n",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `id + 5` cannot be resolved. Did you mean one of the following? [`id`, `address`, `age`, `name`, `nominee`].;\n'Project ['id + 5]\n+- Relation [id#1156,name#1157,age#1158,salary#1159,address#1160,nominee#1161] csv\n",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "employee_data1.select(\"id + 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1857fed3-edd8-47d3-9f0d-69695a746ba7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|(id + 5)|\n+--------+\n|       6|\n|       7|\n|       8|\n|       9|\n|      10|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(col(\"id\") + 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81932624-57e0-47a1-b650-27fd5b0a3458",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n| id|    name|age|\n+---+--------+---+\n|  1|  Manish| 26|\n|  2|  Nikita| 23|\n|  3|  Pritam| 22|\n|  4|Prantosh| 17|\n|  5|  Vikash| 31|\n+---+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(\"id\",\"name\",\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "319b40a9-ccf8-4281-8eac-abd695e563f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n| id|    name|age|\n+---+--------+---+\n|  1|  Manish| 26|\n|  2|  Nikita| 23|\n|  3|  Pritam| 22|\n|  4|Prantosh| 17|\n|  5|  Vikash| 31|\n+---+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(col(\"id\"),col(\"name\"),col(\"age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e1647d3-eb74-43a0-8087-cf02c04c9c06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------------+\n| id|    name|age|     address|\n+---+--------+---+------------+\n|  1|  Manish| 26|       bihar|\n|  2|  Nikita| 23|uttarpradesh|\n|  3|  Pritam| 22|   Bangalore|\n|  4|Prantosh| 17|     Kolkata|\n|  5|  Vikash| 31|        null|\n+---+--------+---+------------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(\"id\",col(\"name\"),employee_data1[\"age\"],employee_data1.address).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3da46724-8df5-4c55-ba97-9edd82bca133",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87c44dfe-d791-4fd1-b52c-23658354f4ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|(id + 5)|\n+--------+\n|       6|\n|       7|\n|       8|\n|       9|\n|      10|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(expr(\"id + 5\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cb6b4b1-e932-4854-a6a6-9d0e0aad94c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------------+\n|employee_id|employee_name|concat(name, address)|\n+-----------+-------------+---------------------+\n|          1|       Manish|          Manishbihar|\n|          2|       Nikita|   Nikitauttarpradesh|\n|          3|       Pritam|      PritamBangalore|\n|          4|     Prantosh|      PrantoshKolkata|\n|          5|       Vikash|                 null|\n+-----------+-------------+---------------------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(expr('id as employee_id'),expr('name as employee_name'),\n",
    "                      expr('concat(name,address)')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f36d0b9-b526-4750-bf55-ff4ab02e1cc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b26f0df-cf5f-4831-bcec-c50f982213ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "employee_data1.createOrReplaceTempView('employee_tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9793bde9-4d39-4b33-8a79-15c0f768bd22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n| id|    name|age|salary|     address| nominee|\n+---+--------+---+------+------------+--------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|  3|  Pritam| 22|150000|   Bangalore|   India|\n|  4|Prantosh| 17|200000|     Kolkata|   India|\n|  5|  Vikash| 31|300000|        null|nominee5|\n+---+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select * from employee_tbl\n",
    "          \"\"\").show() #select all column in spark sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ec02d13-fa78-4037-8a28-b47d234b81cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+\n| id|    name|age|salary|     address| nominee|\n+---+--------+---+------+------------+--------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|  3|  Pritam| 22|150000|   Bangalore|   India|\n|  4|Prantosh| 17|200000|     Kolkata|   India|\n|  5|  Vikash| 31|300000|        null|nominee5|\n+---+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(\"*\").show() #select all column in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4116a4fa-a84b-4354-b47a-95bb2d190e82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n| id|    name|age|\n+---+--------+---+\n|  1|  Manish| 26|\n|  2|  Nikita| 23|\n|  3|  Pritam| 22|\n|  4|Prantosh| 17|\n|  5|  Vikash| 31|\n+---+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          select id, name, age from employee_tbl\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0123dce6-36ff-44cb-973d-84cf178f5b27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: integer (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "750d8d66-f12d-498d-bfe5-2cb52023f2ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Aliasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca7455b2-698d-4b44-acc5-9a944e073883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+\n|employee_id|    name|age|\n+-----------+--------+---+\n|          1|  Manish| 26|\n|          2|  Nikita| 23|\n|          3|  Pritam| 22|\n|          4|Prantosh| 17|\n|          5|  Vikash| 31|\n+-----------+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(col('id').alias('employee_id'),'name','age').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31be88e1-5145-4205-9c93-e49b807c03b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee2bcfe-7152-4987-a370-d3daa9949ad2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+--------+\n| id|    name|age|salary|address| nominee|\n+---+--------+---+------+-------+--------+\n|  4|Prantosh| 17|200000|Kolkata|   India|\n|  5|  Vikash| 31|300000|   null|nominee5|\n+---+--------+---+------+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.filter(col('salary') > 150000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "301363c2-4809-4fee-b381-70a87b2a55ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+--------+\n| id|    name|age|salary|address| nominee|\n+---+--------+---+------+-------+--------+\n|  4|Prantosh| 17|200000|Kolkata|   India|\n|  5|  Vikash| 31|300000|   null|nominee5|\n+---+--------+---+------+-------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.where(col('salary') > 150000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6e05256-7cbe-4bf7-b56a-d4926ea63f35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2960761336320905>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m employee_data1\u001B[38;5;241m.\u001B[39mfilter(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msalary\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m150000\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m18\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:1295\u001B[0m, in \u001B[0;36mColumn.__nonzero__\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m   1294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__nonzero__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m-> 1295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n",
       "\u001B[1;32m   1296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot convert column into bool: please use \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m&\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mor\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1297\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m~\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m when building DataFrame boolean expressions.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1298\u001B[0m     )\n",
       "\n",
       "\u001B[0;31mValueError\u001B[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)\nFile \u001B[0;32m<command-2960761336320905>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m employee_data1\u001B[38;5;241m.\u001B[39mfilter(col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msalary\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m150000\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m col(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mage\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m18\u001B[39m)\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/column.py:1295\u001B[0m, in \u001B[0;36mColumn.__nonzero__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1294\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__nonzero__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1296\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot convert column into bool: please use \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m&\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mand\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m|\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mor\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1297\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m~\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnot\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m when building DataFrame boolean expressions.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1298\u001B[0m     )\n\n\u001B[0;31mValueError\u001B[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
       "errorSummary": "<span class='ansi-red-fg'>ValueError</span>: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "employee_data1.filter(col('salary') > 150000 and col('age') < 18).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83a03253-d2b7-41bb-b67a-16c1e0d24143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+\n| id|    name|age|salary|address|nominee|\n+---+--------+---+------+-------+-------+\n|  4|Prantosh| 17|200000|Kolkata|  India|\n+---+--------+---+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.filter((col('salary') > 150000) & (col('age') < 18)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "270ba195-b2d7-46c2-b1b8-fb5661d40ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc51526d-2b67-4690-951c-9cefc39e05fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+---------+\n| id|    name|age|salary|     address| nominee|last_name|\n+---+--------+---+------+------------+--------+---------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|    Kumar|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|    Kumar|\n|  3|  Pritam| 22|150000|   Bangalore|   India|    Kumar|\n|  4|Prantosh| 17|200000|     Kolkata|   India|    Kumar|\n|  5|  Vikash| 31|300000|        null|nominee5|    Kumar|\n+---+--------+---+------+------------+--------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.select(\"*\", lit(\"Kumar\").alias(\"last_name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87dfba4b-412d-414c-9c66-c619bcaacfa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9174bb47-a934-4f7e-a074-13ced5106369",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+------------+--------+--------+\n| id|    name|age|salary|     address| nominee|sur_name|\n+---+--------+---+------+------------+--------+--------+\n|  1|  Manish| 26| 75000|       bihar|nominee1|   singh|\n|  2|  Nikita| 23|100000|uttarpradesh|nominee2|   singh|\n|  3|  Pritam| 22|150000|   Bangalore|   India|   singh|\n|  4|Prantosh| 17|200000|     Kolkata|   India|   singh|\n|  5|  Vikash| 31|300000|        null|nominee5|   singh|\n+---+--------+---+------+------------+--------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.withColumn(\"sur_name\",lit(\"singh\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2d5d223-f448-415e-af85-2d5ec965bc88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "376c1118-9e36-4d0b-b8cb-ce2000742829",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+------------+--------+\n|employee_id|    name|age|salary|     address| nominee|\n+-----------+--------+---+------+------------+--------+\n|          1|  Manish| 26| 75000|       bihar|nominee1|\n|          2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|          3|  Pritam| 22|150000|   Bangalore|   India|\n|          4|Prantosh| 17|200000|     Kolkata|   India|\n|          5|  Vikash| 31|300000|        null|nominee5|\n+-----------+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.withColumnRenamed(\"id\",\"employee_id\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5ddc301-d459-44fb-bad7-c4ee692a8e47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_emploee_df = employee_data1.withColumnRenamed(\"id\",\"employee_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdb92d87-a358-478e-a3e9-2617dcb8dc8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+------------+--------+\n|employee_id|    name|age|salary|     address| nominee|\n+-----------+--------+---+------+------------+--------+\n|          1|  Manish| 26| 75000|       bihar|nominee1|\n|          2|  Nikita| 23|100000|uttarpradesh|nominee2|\n|          3|  Pritam| 22|150000|   Bangalore|   India|\n|          4|Prantosh| 17|200000|     Kolkata|   India|\n|          5|  Vikash| 31|300000|        null|nominee5|\n+-----------+--------+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "new_emploee_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "126d132b-c648-4c10-a906-691c63cb3d08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Casting Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd88c4eb-f93a-45a9-a2cf-61c80f0b7e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: integer (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe8d302d-c4d1-4a9d-a567-9eadca70aa79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: integer (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.withColumn(\"id\",col(\"id\").cast(\"string\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af113a83-057e-4917-b01e-e6bb736e186e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: long (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.withColumn(\"id\",col(\"id\").cast(\"string\"))\\\n",
    "    .withColumn(\"salary\",col(\"salary\").cast(\"long\"))\\\n",
    "    .printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bb06f93e-06a0-450e-828f-7361ad98790d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Remove Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2403818-4760-440a-a6a1-2e57cb8b3231",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------------+--------+\n|age|salary|     address| nominee|\n+---+------+------------+--------+\n| 26| 75000|       bihar|nominee1|\n| 23|100000|uttarpradesh|nominee2|\n| 22|150000|   Bangalore|   India|\n| 17|200000|     Kolkata|   India|\n| 31|300000|        null|nominee5|\n+---+------+------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_data1.drop('id',col('name')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a209ac2-53fe-4c19-a655-27704b0c6290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d41b3df0-37c7-485f-bac2-a6dfb93cf6df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+\n|emp_id|    name|age|\n+------+--------+---+\n|     1|  Manish| 26|\n|     2|  Nikita| 23|\n|     3|  Pritam| 22|\n|     4|Prantosh| 17|\n|     5|  Vikash| 31|\n+------+--------+---+\n\n"
     ]
    }
   ],
   "source": [
    "# Alias\n",
    "spark.sql(\"\"\"\n",
    "          select id as emp_id, name, age from employee_tbl\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e38f2f99-0a0f-420c-8aef-1f9cc03b1c23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+\n| id|    name|age|salary|address|nominee|\n+---+--------+---+------+-------+-------+\n|  4|Prantosh| 17|200000|Kolkata|  India|\n+---+--------+---+------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter/Where\n",
    "spark.sql(\"\"\"\n",
    "          select * from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fcd91cf-cb84-4a0d-bec6-0d9fa347b58c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+---------+\n| id|    name|age|salary|address|nominee|last_name|\n+---+--------+---+------+-------+-------+---------+\n|  4|Prantosh| 17|200000|Kolkata|  India|    kumar|\n+---+--------+---+------+-------+-------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Literal\n",
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "637d0389-6924-4431-9029-834ef09ac823",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+---------+-------------+\n| id|    name|age|salary|address|nominee|last_name|    full_name|\n+---+--------+---+------+-------+-------+---------+-------------+\n|  4|Prantosh| 17|200000|Kolkata|  India|    kumar|Prantoshkumar|\n+---+--------+---+------+-------+-------+---------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Adding Columns\n",
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name, concat(name,last_name) as full_name from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4de067a-b403-4902-8a37-3a38fec152a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+-------+---------+-------------+-----------+\n| id|    name|age|salary|address|nominee|last_name|    full_name|employee_id|\n+---+--------+---+------+-------+-------+---------+-------------+-----------+\n|  4|Prantosh| 17|200000|Kolkata|  India|    kumar|Prantoshkumar|          4|\n+---+--------+---+------+-------+-------+---------+-------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "#Renaming Columns\n",
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name, concat(name,last_name) as full_name, id as employee_id from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e37aa6aa-bc6c-43e1-9b60-ce4c823750d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: integer (nullable = true)\n |-- address: string (nullable = true)\n |-- nominee: string (nullable = true)\n |-- last_name: string (nullable = false)\n |-- full_name: string (nullable = true)\n |-- id: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# Casting Data type\n",
    "spark.sql(\"\"\"\n",
    "          select *, \"kumar\" as last_name, concat(name,last_name) as full_name, cast(id as string) from employee_tbl where salary > 150000 and age < 18\n",
    "          \"\"\").printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42c3589d-8174-4cdc-90ef-c099ca4948fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Removing Columns - dont write in select statement if no need any columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d58df742-93b5-4a36-b5e0-d9375ea298d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Unique & sorted records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdd6bffe-68a1-4b61-abed-39d522f97ddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data=[(10 ,'Anil',50000, 18),\n",
    "(11 ,'Vikas',75000,  16),\n",
    "(12 ,'Nisha',40000,  18),\n",
    "(13 ,'Nidhi',60000,  17),\n",
    "(14 ,'Priya',80000,  18),\n",
    "(15 ,'Mohit',45000,  18),\n",
    "(16 ,'Rajesh',90000, 10),\n",
    "(17 ,'Raman',55000, 16),\n",
    "(18 ,'Sam',65000,   17),\n",
    "(15 ,'Mohit',45000,  18),\n",
    "(13 ,'Nidhi',60000,  17),      \n",
    "(14 ,'Priya',90000,  18),  \n",
    "(18 ,'Sam',65000,   17)\n",
    "     ]\n",
    "\n",
    "\n",
    "schema = ['id','Name','sal','mngr_id']\n",
    "\n",
    "manager_df = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7fe93e1-231c-4029-9730-4ac6d890f156",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+-------+\n| id|  Name|  sal|mngr_id|\n+---+------+-----+-------+\n| 10|  Anil|50000|     18|\n| 11| Vikas|75000|     16|\n| 12| Nisha|40000|     18|\n| 13| Nidhi|60000|     17|\n| 14| Priya|80000|     18|\n| 15| Mohit|45000|     18|\n| 16|Rajesh|90000|     10|\n| 17| Raman|55000|     16|\n| 18|   Sam|65000|     17|\n| 15| Mohit|45000|     18|\n| 13| Nidhi|60000|     17|\n| 14| Priya|90000|     18|\n| 18|   Sam|65000|     17|\n+---+------+-----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "813a2836-c926-43d5-a008-97b7f2d6b78d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+-------+\n| id|  Name|  sal|mngr_id|\n+---+------+-----+-------+\n| 10|  Anil|50000|     18|\n| 12| Nisha|40000|     18|\n| 11| Vikas|75000|     16|\n| 13| Nidhi|60000|     17|\n| 15| Mohit|45000|     18|\n| 14| Priya|80000|     18|\n| 16|Rajesh|90000|     10|\n| 17| Raman|55000|     16|\n| 18|   Sam|65000|     17|\n| 14| Priya|90000|     18|\n+---+------+-----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efa28f12-1a36-4acd-bc16-df6afc6bfe0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: 10"
     ]
    }
   ],
   "source": [
    "manager_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69a185bf-3f5d-4ad7-83c9-bf7831d7ebbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: 13"
     ]
    }
   ],
   "source": [
    "manager_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a09f1da7-eb00-456f-9781-56f9df182466",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1195057310164348>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mmanager_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistinct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mname\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "\u001B[0;31mTypeError\u001B[0m: distinct() takes 1 positional argument but 3 were given"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1195057310164348>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmanager_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistinct\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mname\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\n\u001B[0;31mTypeError\u001B[0m: distinct() takes 1 positional argument but 3 were given",
       "errorSummary": "<span class='ansi-red-fg'>TypeError</span>: distinct() takes 1 positional argument but 3 were given",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "manager_df.distinct(\"id\",\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39e50f53-4ac4-4c1c-97a6-7b02d494bfb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n| id|  name|\n+---+------+\n| 10|  Anil|\n| 11| Vikas|\n| 12| Nisha|\n| 13| Nidhi|\n| 15| Mohit|\n| 14| Priya|\n| 17| Raman|\n| 16|Rajesh|\n| 18|   Sam|\n+---+------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.select(\"id\",\"name\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64fbcc1f-01bc-41ec-92ce-569ed074d786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dropped_manager_df = manager_df.dropDuplicates([\"id\",\"name\",\"sal\",\"mngr_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83358f81-6c6e-483e-a98c-15c06fea1ae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+-------+\n| id|  Name|  sal|mngr_id|\n+---+------+-----+-------+\n| 10|  Anil|50000|     18|\n| 12| Nisha|40000|     18|\n| 11| Vikas|75000|     16|\n| 13| Nidhi|60000|     17|\n| 15| Mohit|45000|     18|\n| 14| Priya|80000|     18|\n| 16|Rajesh|90000|     10|\n| 17| Raman|55000|     16|\n| 18|   Sam|65000|     17|\n| 14| Priya|90000|     18|\n+---+------+-----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "dropped_manager_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adb10619-8dd7-4889-a5b0-a2afbd109b3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c1ff2c6-0022-4b0e-9b13-7dbd1dff43aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+-------+\n| id|  Name|  sal|mngr_id|\n+---+------+-----+-------+\n| 12| Nisha|40000|     18|\n| 15| Mohit|45000|     18|\n| 15| Mohit|45000|     18|\n| 10|  Anil|50000|     18|\n| 17| Raman|55000|     16|\n| 13| Nidhi|60000|     17|\n| 13| Nidhi|60000|     17|\n| 18|   Sam|65000|     17|\n| 18|   Sam|65000|     17|\n| 11| Vikas|75000|     16|\n| 14| Priya|80000|     18|\n| 16|Rajesh|90000|     10|\n| 14| Priya|90000|     18|\n+---+------+-----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.sort(col(\"sal\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e25df4c-d535-41b5-814a-1bc424a58abb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+-------+\n| id|  Name|  sal|mngr_id|\n+---+------+-----+-------+\n| 16|Rajesh|90000|     10|\n| 14| Priya|90000|     18|\n| 14| Priya|80000|     18|\n| 11| Vikas|75000|     16|\n| 18|   Sam|65000|     17|\n| 18|   Sam|65000|     17|\n| 13| Nidhi|60000|     17|\n| 13| Nidhi|60000|     17|\n| 17| Raman|55000|     16|\n| 10|  Anil|50000|     18|\n| 15| Mohit|45000|     18|\n| 15| Mohit|45000|     18|\n| 12| Nisha|40000|     18|\n+---+------+-----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.sort(col(\"sal\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93c1334d-5c0a-47f4-9a7d-af2e64997c55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----+-------+\n| id|  Name|  sal|mngr_id|\n+---+------+-----+-------+\n| 16|Rajesh|90000|     10|\n| 14| Priya|90000|     18|\n| 14| Priya|80000|     18|\n| 11| Vikas|75000|     16|\n| 18|   Sam|65000|     17|\n| 18|   Sam|65000|     17|\n| 13| Nidhi|60000|     17|\n| 13| Nidhi|60000|     17|\n| 17| Raman|55000|     16|\n| 10|  Anil|50000|     18|\n| 15| Mohit|45000|     18|\n| 15| Mohit|45000|     18|\n| 12| Nisha|40000|     18|\n+---+------+-----+-------+\n\n"
     ]
    }
   ],
   "source": [
    "manager_df.sort(col(\"sal\").desc(),col(\"Name\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9dbdc7d9-53eb-4596-84c8-41f3942b68c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# leetcode question - https://leetcode.com/problems/find-customer-referee/description/?envType=study-plan-v2&envId=top-sql-50\n",
    "\n",
    "\n",
    "leet_code_data = [\n",
    "    (1, 'Will', None),\n",
    "    (2, 'Jane', None),\n",
    "    (3, 'Alex', 2),\n",
    "    (4, 'Bill', None),\n",
    "    (5, 'Zack', 1),\n",
    "    (6, 'Mark', 2)\n",
    "]\n",
    "\n",
    "schema = ['id','name','referee_id']\n",
    "\n",
    "leetcode_df = spark.createDataFrame(data=leet_code_data,schema=schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f4bcbb-e962-459f-994b-85239e22413d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Table: Customer\n",
    "\n",
    "+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| id          | int     |\n",
    "| name        | varchar |\n",
    "| referee_id  | int     |\n",
    "+-------------+---------+\n",
    "In SQL, id is the primary key column for this table.\n",
    "Each row of this table indicates the id of a customer, their name, and the id of the customer who referred them.\n",
    " \n",
    "\n",
    "Find the names of the customer that are not referred by the customer with id = 2.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Customer table:\n",
    "+----+------+------------+\n",
    "| id | name | referee_id |\n",
    "+----+------+------------+\n",
    "| 1  | Will | null       |\n",
    "| 2  | Jane | null       |\n",
    "| 3  | Alex | 2          |\n",
    "| 4  | Bill | null       |\n",
    "| 5  | Zack | 1          |\n",
    "| 6  | Mark | 2          |\n",
    "+----+------+------------+\n",
    "Output: \n",
    "+------+\n",
    "| name |\n",
    "+------+\n",
    "| Will |\n",
    "| Jane |\n",
    "| Bill |\n",
    "| Zack |\n",
    "+------+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74565fbc-4303-4c09-b1c1-96224059ffd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n|name|\n+----+\n|Will|\n|Jane|\n|Bill|\n|Zack|\n+----+\n\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for customers where referee_id is either null or not equal to 2\n",
    "result_df = leetcode_df.filter((leetcode_df.referee_id.isNull()) | (leetcode_df.referee_id != 2))\n",
    "\n",
    "# Select only the 'name' column for the result\n",
    "result_df = result_df.select('name')\n",
    "\n",
    "# Show the result\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34027fa4-b592-4c3a-bd8b-af5574f4ea6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transformation_in_spark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
