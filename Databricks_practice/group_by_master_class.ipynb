{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "affe00c8-3aff-415b-9cf9-d9e48d56472e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60486a8d-46cb-4055-b274-e819a40f7d59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+------+---------+\n| id|   name|salary|     dept|\n+---+-------+------+---------+\n|  1| manish| 50000|       IT|\n|  2| vikash| 60000|    sales|\n|  3|raushan| 70000|marketing|\n|  4| mukesh| 80000|       IT|\n|  5| pritam| 90000|    sales|\n|  6| nikita| 45000|marketing|\n|  7| ragini| 55000|marketing|\n|  8| rakesh|100000|       IT|\n|  9| aditya| 65000|       IT|\n| 10|  rahul| 50000|marketing|\n+---+-------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [(1,'manish',50000,'IT'),\n",
    "(2,'vikash',60000,'sales'),\n",
    "(3,'raushan',70000,'marketing'),\n",
    "(4,'mukesh',80000,'IT'),\n",
    "(5,'pritam',90000,'sales'),\n",
    "(6,'nikita',45000,'marketing'),\n",
    "(7,'ragini',55000,'marketing'),\n",
    "(8,'rakesh',100000,'IT'),\n",
    "(9,'aditya',65000,'IT'),\n",
    "(10,'rahul',50000,'marketing')]\n",
    "\n",
    "schema = ['id','name','salary','dept']\n",
    "\n",
    "emp_df = spark.createDataFrame(data=data,schema=schema)\n",
    "\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed6ada67-d372-4a3b-ac75-18ed3197912b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n|     dept|sum(salary)|\n+---------+-----------+\n|       IT|     295000|\n|    sales|     150000|\n|marketing|     220000|\n+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.groupby(\"dept\")\\\n",
    "    .agg(sum('salary')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c29b13-bee5-43f3-84ab-a8b20e1f2386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "emp_df.createOrReplaceTempView('emp_tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "114f8814-8ee9-4ca5-8fef-9953cd1f74eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n|     dept|sum(salary)|\n+---------+-----------+\n|       IT|       null|\n|    sales|       null|\n|marketing|       null|\n+---------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "          \n",
    "        select dept,sum(\"salary\")\n",
    "        from emp_tbl\n",
    "        group by dept\n",
    "\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e640c003-b655-4fae-b0c3-b05c97dd525e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# calculate the total salary grouped by dept and country\n",
    "\n",
    "# Define the data\n",
    "data = [\n",
    "    (1, 'manish', 50000, 'IT', 'india'),\n",
    "    (2, 'vikash', 60000, 'sales', 'us'),\n",
    "    (3, 'raushan', 70000, 'marketing', 'india'),\n",
    "    (4, 'mukesh', 80000, 'IT', 'us'),\n",
    "    (5, 'pritam', 90000, 'sales', 'india'),\n",
    "    (6, 'nikita', 45000, 'marketing', 'us'),\n",
    "    (7, 'ragini', 55000, 'marketing', 'india'),\n",
    "    (8, 'rakesh', 100000, 'IT', 'us'),\n",
    "    (9, 'aditya', 65000, 'IT', 'india'),\n",
    "    (10, 'rahul', 50000, 'marketing', 'us')\n",
    "]\n",
    "\n",
    "# Define the schema\n",
    "schema = ['id', 'name', 'salary', 'dept', 'country']\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26136ed6-bb83-4ac6-a4ae-e63842c7ef63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51632da6-a918-4672-a647-0aba7fda1ec8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+------------+\n|     dept|country|total_salary|\n+---------+-------+------------+\n|       IT|  india|      115000|\n|       IT|     us|      180000|\n|marketing|  india|      125000|\n|marketing|     us|       95000|\n|    sales|  india|       90000|\n|    sales|     us|       60000|\n+---------+-------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the WindowSpec for grouping by dept and country\n",
    "window_spec = Window.partitionBy('dept', 'country')\n",
    "\n",
    "# Calculate the total salary using the Window function\n",
    "df_with_total_salary = df.withColumn('total_salary', sum('salary').over(window_spec))\n",
    "\n",
    "# Drop duplicate rows to show unique dept and country combinations with total salary\n",
    "result_df = df_with_total_salary.select('dept', 'country', 'total_salary').distinct()\n",
    "\n",
    "# Show the result\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ebb526b-e771-42bf-a28b-f324e3f37697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "group_by_master_class",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
