{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c9e336d-c218-44ea-b6db-48614803983a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Application  - sparksubmit command to cluster  to run job is call application\n",
    "# job - each action is called job\n",
    "# stage - no. of transformations is called stage\n",
    "# task - actual execution is called task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f14f541-13aa-474a-b5e0-09e87d30f3eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+---+----------+-----------+------+------------+\n|EmployeeID|             Name|Age|Department|JoiningDate|Salary|        City|\n+----------+-----------------+---+----------+-----------+------+------------+\n|         1|       Jon Rivera| 56|     Sales| 2024-04-29|121250|     Houston|\n|         2|   Nicole Daniels| 46|        HR| 2024-04-01|138633|    New York|\n|         3| Monique Sullivan| 32|   Finance| 2020-05-02| 83619|Philadelphia|\n|         4|     James Wright| 60| Marketing| 2023-02-21|129751|    New York|\n|         5|  Nicole Williams| 25|     Sales| 2018-04-29|123193|     Chicago|\n|         6|      David Bates| 38|     Sales| 2019-03-12| 98719|      Dallas|\n|         7|    Matthew Riggs| 56| Marketing| 2019-11-06| 71156| Los Angeles|\n|         8|     Wendy Powers| 36|Operations| 2023-07-30| 73901|      Dallas|\n|         9|   Thomas Collins| 40|   Support| 2018-10-12| 30418|Philadelphia|\n|        10|      Joshua Wong| 28|        IT| 2022-05-17| 89252| San Antonio|\n|        11|   Dakota Shields| 28|        HR| 2018-02-24|114528|      Dallas|\n|        12|    Angelica Wade| 41|        HR| 2015-06-29|130914|     Phoenix|\n|        13|   Allison Miller| 53| Marketing| 2019-09-19|108950|      Dallas|\n|        14|     Ryan Morales| 57| Marketing| 2021-05-13|130007|      Dallas|\n|        15| Elizabeth Lawson| 41|Operations| 2022-11-12| 94927| Los Angeles|\n|        16|  Diamond Gardner| 20|     Sales| 2016-04-01| 71276|     Houston|\n|        17|      Cindy Avila| 39|        HR| 2018-06-03| 46127|     Houston|\n|        18|      April Heath| 19|     Sales| 2023-10-08| 43061| Los Angeles|\n|        19|Gilbert Fernandez| 41|   Finance| 2015-02-02|121576|    New York|\n|        20|    Tyler Gregory| 61|     Sales| 2018-03-27| 70422|     Phoenix|\n+----------+-----------------+---+----------+-----------+------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"dbfs:/FileStore/demo_folder/employee_dataset.csv\",header=True,inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd0bce0-7de3-4169-b436-0c45d1722428",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Partitioning and Parallelism Optimization in Spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"PartitioningOptimization\").getOrCreate()\n",
    "empDf = spark.read.csv(\"dbfs:/FileStore/demo_folder/employee_dataset.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c40366e-46d2-41c0-8a38-c10fd7ce78ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "empDf.write.mode(\"overwrite\").partitionBy(\"Department\").parquet(\"dbfs:/FileStore/demo_folder13/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c52a24-2271-44df-b619-f3beb1537bb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+---+-----------+------+------------+\n|EmployeeID|             Name|Age|JoiningDate|Salary|        City|\n+----------+-----------------+---+-----------+------+------------+\n|   1275135|  Natalie Bradley| 58| 2020-10-10|115570|    New York|\n|   1275152|     Kyle Gregory| 53| 2018-06-13|149212|     Houston|\n|   1275159|   Teresa Compton| 21| 2023-11-12|104425|     Phoenix|\n|   1275177|     John Fuentes| 24| 2022-08-18| 34800|Philadelphia|\n|   1275182|    Hannah Rivera| 62| 2019-04-07| 97046|     Houston|\n|   1275185|   Jennifer Braun| 46| 2015-05-12|127498|      Dallas|\n|   1275191| Christian Carter| 24| 2022-03-19| 39445| Los Angeles|\n|   1275205|     Anthony Luna| 51| 2016-04-23|109995|      Dallas|\n|   1275208| Jennifer Mcclain| 49| 2023-06-06| 86345| Los Angeles|\n|   1275214|Christopher Hodge| 48| 2018-08-31| 83242|     Houston|\n|   1275217|   Alejandro Chan| 49| 2015-11-01|112688|      Dallas|\n|   1275218|Alexander Vaughan| 40| 2018-01-18| 55965|    New York|\n|   1275233|   Carolyn Snyder| 45| 2016-05-13|126100|     Phoenix|\n|   1275238|     Rachel Garza| 60| 2018-02-11| 84826|Philadelphia|\n|   1275240|        Adam Gill| 42| 2023-09-10| 36363| Los Angeles|\n|   1275261|     Linda Garcia| 39| 2024-02-05| 99515|    New York|\n|   1275264|   Brandon Morton| 37| 2018-08-27|131310|     Houston|\n|   1275286|  Shelly Morrison| 18| 2017-10-04|142532|      Dallas|\n|   1275292|    Thomas Thomas| 52| 2023-04-06| 48482| San Antonio|\n|   1275300|     Maria Bowman| 22| 2020-10-25|135660|      Dallas|\n+----------+-----------------+---+-----------+------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"dbfs:/FileStore/demo_folder13/Department=Finance/part-00001-tid-4893172150368010465-0d2058e1-d01a-41f7-b6af-bcc0bef853a5-223-1.c000.snappy.parquet\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81bc189b-0236-42d0-97a1-d0e018d6dae9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default number of partitions: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"Default number of partitions: {empDf.rdd.getNumPartitions()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b97dc796-3cd6-4bbf-bbe5-f46d6d67377b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n|Department|  count|\n+----------+-------+\n|     Sales|1428770|\n|        HR|1430234|\n|   Finance|1427169|\n| Marketing|1428760|\n|        IT|1429511|\n|   Support|1428311|\n|Operations|1427245|\n+----------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "# Increase parallelism During Shuffles\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\",200)\n",
    "\n",
    "agg_df = empDf.groupBy(\"Department\").count()\n",
    "agg_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f295d443-6393-4b25-97cc-b43c5c4f0b0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n'Aggregate ['Department], ['Department, count(1) AS count#488L]\n+- Relation [EmployeeID#459,Name#460,Age#461,Department#462,JoiningDate#463,Salary#464,City#465] csv\n\n== Analyzed Logical Plan ==\nDepartment: string, count: bigint\nAggregate [Department#462], [Department#462, count(1) AS count#488L]\n+- Relation [EmployeeID#459,Name#460,Age#461,Department#462,JoiningDate#463,Salary#464,City#465] csv\n\n== Optimized Logical Plan ==\nAggregate [Department#462], [Department#462, count(1) AS count#488L]\n+- Project [Department#462]\n   +- Relation [EmployeeID#459,Name#460,Age#461,Department#462,JoiningDate#463,Salary#464,City#465] csv\n\n== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[Department#462], functions=[finalmerge_count(merge count#499L) AS count(1)#487L], output=[Department#462, count#488L])\n   +- Exchange hashpartitioning(Department#462, 200), ENSURE_REQUIREMENTS, [plan_id=508]\n      +- HashAggregate(keys=[Department#462], functions=[partial_count(1) AS count#499L], output=[Department#462, count#499L])\n         +- FileScan csv [Department#462] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/FileStore/demo_folder/employee_dataset.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Department:string>\n\n"
     ]
    }
   ],
   "source": [
    "agg_df.explain(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc39e091-7cc4-4e23-b6d9-8bd5bc04aed6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "repartition_df = empDf.repartition(100,col(\"Department\"))\n",
    "\n",
    "result_df = repartition_df.groupBy(col(\"Department\")).agg(avg(\"Salary\").alias(\"avg_Salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6511f2b-4baa-4d49-b726-1c718eb957aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "repartition_df.write.mode(\"overwrite\").parquet(\"dbfs:/FileStore/demo_folder10/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab37a3b0-3cb7-43db-ae51-a622ebd98114",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+---+----------+-----------+------+------------+\n|EmployeeID|                Name|Age|Department|JoiningDate|Salary|        City|\n+----------+--------------------+---+----------+-----------+------+------------+\n|         4|        James Wright| 60| Marketing| 2023-02-21|129751|    New York|\n|         7|       Matthew Riggs| 56| Marketing| 2019-11-06| 71156| Los Angeles|\n|        13|      Allison Miller| 53| Marketing| 2019-09-19|108950|      Dallas|\n|        14|        Ryan Morales| 57| Marketing| 2021-05-13|130007|      Dallas|\n|        26|      Jason Marshall| 29| Marketing| 2018-11-09| 85932|      Dallas|\n|        40|      Elizabeth Love| 38| Marketing| 2016-01-17| 61988|      Dallas|\n|        41|Christopher Cruz DDS| 26| Marketing| 2016-11-22|144849|      Dallas|\n|        80|   Anthony Hernandez| 57| Marketing| 2016-01-04| 47130| Los Angeles|\n|        83|       Michelle Neal| 62| Marketing| 2020-11-28| 40823|     Phoenix|\n|        92|         Alexis Wood| 32| Marketing| 2020-04-26|129484| San Antonio|\n|        97|        Oscar Little| 26| Marketing| 2015-08-11|100640| San Antonio|\n|        98|        Frank Phelps| 41| Marketing| 2022-04-11| 85610|    New York|\n|       105|  Dr. Lawrence Perez| 25| Marketing| 2022-07-09| 74334|     Chicago|\n|       127|     Crystal Skinner| 44| Marketing| 2018-07-07|123185|     Phoenix|\n|       128|        Amber Morris| 52| Marketing| 2022-12-05| 84249| Los Angeles|\n|       141|         Jaime Smith| 26| Marketing| 2018-12-29| 55717| San Antonio|\n|       143|     Alexis Robinson| 32| Marketing| 2022-10-26| 39399|      Dallas|\n|       148|           Ray Rocha| 56| Marketing| 2021-08-20|112583| San Antonio|\n|       152|        Ronald Novak| 54| Marketing| 2021-05-05|130793|Philadelphia|\n|       155|      Kimberly Mcgee| 62| Marketing| 2020-12-30| 42011| San Antonio|\n+----------+--------------------+---+----------+-----------+------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet('dbfs:/FileStore/demo_folder10/part-00021-tid-851087917284295486-16a99efb-7717-4fd9-b024-3299536d357a-77-1-c000.snappy.parquet',header=True,inferSchema=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0618070-645c-423a-bea4-879074e377af",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_df = result_df.coalesce(3)\n",
    "\n",
    "final_df.write.mode(\"overwrite\").parquet(\"dbfs:/FileStore/demo_folder12/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cd0c2c8-25cb-4b06-b54e-608b44107fb0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n|Department|       avg_Salary|\n+----------+-----------------+\n|     Sales|90004.43771495762|\n| Marketing|89978.62071866513|\n|        IT|89968.35851910198|\n+----------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.parquet(\"dbfs:/FileStore/demo_folder12/part-00000-tid-1762136447601742868-a192849b-c39b-4ed3-8782-5e42f2a8666a-216-1-c000.snappy.parquet\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca02d58a-edb3-4908-bc9f-b9a170ae0c64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2789666227908671>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m newDf \u001B[38;5;241m=\u001B[39m empDf\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDepartment\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m----> 2\u001B[0m newDf\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'GroupedData' object has no attribute 'show'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-2789666227908671>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m newDf \u001B[38;5;241m=\u001B[39m empDf\u001B[38;5;241m.\u001B[39mgroupBy(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDepartment\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m newDf\u001B[38;5;241m.\u001B[39mshow()\n\n\u001B[0;31mAttributeError\u001B[0m: 'GroupedData' object has no attribute 'show'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'GroupedData' object has no attribute 'show'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "newDf = empDf.groupBy(\"Department\")\n",
    "newDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9554e73a-d90e-4b56-87d7-f250741440fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark4.4",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
